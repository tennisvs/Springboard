{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Submission File - Score 0.410856 Private\n\nThis is the submission file to submit the models built to the [Kaggle Competition](https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction). I have to thank Google for Tensorflow and the GPU usuage for training the models and [Baurzhan Urazalinov](https://www.kaggle.com/baurzhanurazalinov), who helped build and design these models in tensorflow.\n\nThe submission code consists of 3 parts: \n1. **Tdcsfog Model**: Here we define the tdcsfog model, then load tdcsfog test data and predict targets. Located at `/kaggle/input/defog-freezing-gait-models/025_0.355_0.816_0.1436_model.h5`\n2. **Defog Model**: Here we define the defog model, then load defog test data and predict targets. Located at `/kaggle/input/tfog-freezing-gait-models/016_0.557_0.893_0.0798_model.h5`\n3. Submission: Here the predicted values are collected, uniformly averaged (if several models were used), then the submission.csv is created.\n\nBoth of these models where built and saved using Google's GPU P100 availble on Kaggle for this competition. You can find the saved models in `/kaggle/input/tfog-freezing-gait-models` and `/kaggle/input/defog-freezing-gait-models`.","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries and Utilities\n\nWe will import the files and utility files.","metadata":{}},{"cell_type":"code","source":"import os \nimport math\n\nimport numpy as np \nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom joblib import Parallel, delayed","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Files\nHere we import the test files we will need to run predicitions on. They are in seperate locations for tdcsfog and defog.","metadata":{}},{"cell_type":"code","source":"all_submissions = [] \n\ntsfog_ids = [fname.split('.')[0] for fname in os.listdir('/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog')] \ndefog_ids = [fname.split('.')[0] for fname in os.listdir('/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/defog')] ","metadata":{"execution":{"iopub.status.busy":"2023-06-25T20:31:27.257844Z","iopub.execute_input":"2023-06-25T20:31:27.258660Z","iopub.status.idle":"2023-06-25T20:31:27.274188Z","shell.execute_reply.started":"2023-06-25T20:31:27.258619Z","shell.execute_reply":"2023-06-25T20:31:27.273202Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Functions\n\nFirst we will set up the parameters for our Tfog model. These are the same parameters used in the training file located within this folder.\n\nJust like before we are going to define some functions. \n\n1. `sample_normalize` is a function that we use to take one sample(file in this case) and standardize the values around 0 for each accelometer column (AccV, AccML, AccAP).\n2. `get_blocks` is our function to input series values into our model in blocks. First the block is padded is it divisible by `CFG['block_size']`. Then it gets the blocks by `CFG['block_stride']`, returning the blocks in that order. So the first block is 'series[0:15552, :]', second block is 'series[972:16524, :]' so on, so forth. These batch sizes are set by the GPU.\n","metadata":{}},{"cell_type":"code","source":"CFG = {'TPU': 0,\n       'block_size': 15552, \n       'block_stride': 15552//16,\n       'patch_size': 18, \n       \n       'fog_model_dim': 320,\n       'fog_model_num_heads': 6,\n       'fog_model_num_encoder_layers': 5,\n       'fog_model_num_lstm_layers': 2,\n       'fog_model_first_dropout': 0.1,\n       'fog_model_encoder_dropout': 0.1,\n       'fog_model_mha_dropout': 0.0,\n      }\n\nassert CFG['block_size'] % CFG['patch_size'] == 0\nassert CFG['block_size'] % CFG['block_stride'] == 0\n\ndef sample_normalize(sample):\n    mean = tf.math.reduce_mean(sample)\n    std = tf.math.reduce_std(sample)\n    sample = tf.math.divide_no_nan(sample-mean, std)\n    \n    return sample.numpy()\n\ndef get_blocks(series, columns):\n    series = series.copy()\n    series = series[columns]\n    series = series.values\n    series = series.astype(np.float32)\n    \n    block_count = math.ceil(len(series) / CFG['block_size'])\n    \n    series = np.pad(series, pad_width=[[0, block_count*CFG['block_size']-len(series)], [0, 0]])\n    \n    block_begins = list(range(0, len(series), CFG['block_stride']))\n    block_begins = [x for x in block_begins if x+CFG['block_size'] <= len(series)]\n    \n    blocks = []\n    for begin in block_begins:\n        values = series[begin:begin + CFG['block_size']]\n        blocks.append({'begin': begin,\n                       'end': begin + ['block_size'],\n                       'values': values})\n    \n    return blocks\n\n# If using GPUs/TPUs on the Kaggle Server\nGPU_BATCH_SIZE = 4\nTPU_BATCH_SIZE = GPU_BATCH_SIZE * 8\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-25T20:31:27.276234Z","iopub.execute_input":"2023-06-25T20:31:27.276654Z","iopub.status.idle":"2023-06-25T20:31:33.452004Z","shell.execute_reply.started":"2023-06-25T20:31:27.276616Z","shell.execute_reply":"2023-06-25T20:31:33.451054Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Models:\n\nThe models are a combination of transformer encoder, which you can read about [here](https://arxiv.org/pdf/1706.03762.pdf) and bi-directional LSTMs. The reasoning behind choosing this, based off EDTA and me trying simple models is as follows:\n- Reason for LSTMs: Based of EDTA, its becomes evident that there is a clear spike in a certain value and that triggers a fog event. LSTMs made sense for this. In addition, it came to my attention that the event also was stopped at future point in the future of the reading, and hence why bidirection LSTMs were used. However, these are memory/computationally expensive, and had to rely on others for the code here.\n- Limited the data, I did not use any of the subject data, or medication data. The community stated that this data had limited effect. In my simplier models, I tried combine a single directional LSTM with subject data, it had little impact.\n- Transformer: this is the part of model I relied on help from others in the Kaggle community\n>\"a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output.\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\" - [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)\n- No features: outside of normalization, bidirectional LSTMs are memory and computationally intensive, limiting the resolution is key here. In simpler models I created, I was not performing nearly as well.\n- During training, there is slight randomize rolling of positional encoding was done here,as done by the [Baurzhan Urazalinov](https://www.kaggle.com/baurzhanurazalinov). I decided to keep it here.\n\n### Tfog Model","metadata":{}},{"cell_type":"code","source":"class EncoderLayer(tf.keras.layers.Layer):\n    def __init__(self):\n        super().__init__()\n    \n        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=CFG['fog_model_num_heads'], key_dim=CFG['fog_model_dim'], dropout=CFG['fog_model_mha_dropout'])\n        \n        self.add = tf.keras.layers.Add()\n        \n        self.layernorm = tf.keras.layers.LayerNormalization()\n        \n        self.seq = tf.keras.Sequential([tf.keras.layers.Dense(CFG['fog_model_dim'], activation='relu'), \n                                        tf.keras.layers.Dropout(CFG['fog_model_encoder_dropout']), \n                                        tf.keras.layers.Dense(CFG['fog_model_dim']), \n                                        tf.keras.layers.Dropout(CFG['fog_model_encoder_dropout']),\n                                       ])\n        \n    def call(self, x):\n        attn_output = self.mha(query=x, key=x, value=x)\n        x = self.add([x, attn_output])\n        x = self.layernorm(x)\n        x = self.add([x, self.seq(x)])\n        x = self.layernorm(x)\n        \n        return x\n    \n# FOGEncoder is a combination of transformer encoder (D=320, H=6, L=5) and two BidirectionalLSTM layers\n\n\nclass FOGEncoder(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        \n        self.first_linear = tf.keras.layers.Dense(CFG['fog_model_dim'])\n        \n        self.add = tf.keras.layers.Add()\n        \n        self.first_dropout = tf.keras.layers.Dropout(CFG['fog_model_first_dropout'])\n        \n        self.enc_layers = [EncoderLayer() for _ in range(CFG['fog_model_num_encoder_layers'])]\n        \n        self.lstm_layers = [tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(CFG['fog_model_dim'], return_sequences=True)) for _ in range(CFG['fog_model_num_lstm_layers'])]\n        \n        self.sequence_len = CFG['block_size'] // CFG['patch_size']\n        self.pos_encoding = tf.Variable(initial_value=tf.random.normal(shape=(1, self.sequence_len, CFG['fog_model_dim']), stddev=0.02), trainable=True)\n        \n    def call(self, x, training=None): # (GPU_BATCH_SIZE, CFG['block_size'] // CFG['patch_size'], CFG['patch_size']*3), Example shape (4, 864, 54)\n        x = x / 25.0 # Normalization attempt in the segment [-1, 1]\n        x = self.first_linear(x) # (GPU_BATCH_SIZE, CFG['block_size'] // CFG['patch_size'], CFG['fog_model_dim']), Example shape (4, 864, 320)\n          \n        if training: # augmentation by randomly roll of the position encoding tensor\n            random_pos_encoding = tf.roll(tf.tile(self.pos_encoding, multiples=[GPU_BATCH_SIZE, 1, 1]), \n                                          shift=tf.random.uniform(shape=(GPU_BATCH_SIZE,), minval=-self.sequence_len, maxval=0, dtype=tf.int32),\n                                          axis=GPU_BATCH_SIZE * [1],\n                                          )\n            x = self.add([x, random_pos_encoding])\n        \n        else: # without augmentation \n            x = self.add([x, tf.tile(self.pos_encoding, multiples=[GPU_BATCH_SIZE, 1, 1])])\n            \n        x = self.first_dropout(x)\n        \n        for i in range(CFG['fog_model_num_encoder_layers']): x = self.enc_layers[i](x) # (GPU_BATCH_SIZE, CFG['block_size'] // CFG['patch_size'], CFG['fog_model_dim']), Example shape (4, 864, 320)\n        for i in range(CFG['fog_model_num_lstm_layers']): x = self.lstm_layers[i](x) # (GPU_BATCH_SIZE, CFG['block_size'] // CFG['patch_size'], CFG['fog_model_dim']*2), Example shape (4, 864, 640)\n            \n        return x\n    \nclass FOGModel(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        \n        self.encoder = FOGEncoder()\n        self.last_linear = tf.keras.layers.Dense(3) \n        \n    def call(self, x):\n        x = self.encoder(x) \n        x = self.last_linear(x) \n        x = tf.nn.sigmoid(x)\n        \n        return x\n    \nWEIGHTS = '/kaggle/input/tfog-freezing-gait-models/016_0.557_0.893_0.0798_model.h5' # TDCSFOG weights\n    \nmodel = FOGModel()\nmodel.build(input_shape=(GPU_BATCH_SIZE, CFG['block_size'] // CFG['patch_size'], CFG['patch_size']*3))\nif len(WEIGHTS): model.load_weights(WEIGHTS)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### PredicitinFnCallback: Tfog\n\nHere we use PredictionFnCallback. This allows us to:\n1. Load test data\n2. Model data preparation\n3. Prediction","metadata":{}},{"cell_type":"code","source":"class PredictionFnCallback(tf.keras.callbacks.Callback):\n    \n    def __init__(self, prediction_ids, model=None, verbose=0):\n        \n        if not model is None: self.model = model\n        self.verbose = verbose\n         \n        def init(Id, path):\n            series = pd.read_csv(path).reset_index(drop=True)\n            series['Id'] = Id\n            series['AccV'] = sample_normalize(series['AccV'].values)\n            series['AccML'] = sample_normalize(series['AccML'].values)\n            series['AccAP'] = sample_normalize(series['AccAP'].values)\n            \n            series_blocks=[]\n            for block in get_blocks(series, ['AccV', 'AccML', 'AccAP']): # Example shape (15552, 3)\n                values = tf.reshape(block['values'], shape=(CFG['block_size'] // CFG['patch_size'], CFG['patch_size'], 3)) # Example shape (864, 18, 3)\n                values = tf.reshape(values, shape=(CFG['block_size'] // CFG['patch_size'], CFG['patch_size']*3)) # Example shape (864, 54)\n                values = tf.expand_dims(values, axis=0) # Example shape (1, 864, 54)\n                \n                self.blocks.append(values)\n                series_blocks.append((self.blocks_counter, block['begin'], block['end']))\n                self.blocks_counter += 1\n            \n            description = {}\n            description['series'] = series\n            description['series_blocks'] = series_blocks\n            self.descriptions.append(description)\n            \n        self.descriptions = []\n        self.blocks = [] \n        self.blocks_counter=0 \n        \n        tsfog_ids = prediction_ids\n        tsfog_paths = [f'/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog/{tsfog_id}.csv' for tsfog_id in tsfog_ids]\n        for tsfog_id, tsfog_path in tqdm(zip(tsfog_ids, tsfog_paths), total=len(tsfog_ids), desc='PredictionFnCallback Initialization', disable=1-verbose): \n            init(tsfog_id, tsfog_path)\n            \n        self.blocks = tf.concat(self.blocks, axis=0) # Example shape (self.blocks_counter, 864, 54)\n        \n        '''\n        self.blocks is padded so that the final length is divisible by inference batch size for error-free operation of model.predict function\n        Padded values have no effect on the predictions\n        \n        '''\n        \n        self.blocks = tf.pad(self.blocks, \n                             paddings=[[0, math.ceil(self.blocks_counter / (TPU_BATCH_SIZE if CFG['TPU'] else GPU_BATCH_SIZE))*(TPU_BATCH_SIZE if CFG['TPU'] else GPU_BATCH_SIZE)-self.blocks_counter], \n                                                    [0, 0], \n                                                    [0, 0],\n                                      ]) # Example shape (self.blocks_counter+pad_value, 864, 54)\n        \n        print(f'\\n[EventPredictionFnCallback Initialization] [Series] {len(self.descriptions)} [Blocks] {self.blocks_counter}\\n')\n    \n    def prediction(self):\n        predictions = model.predict(self.blocks, batch_size=TPU_BATCH_SIZE if CFG['TPU'] else GPU_BATCH_SIZE, verbose=self.verbose) # Example shape (self.blocks_counter+pad_value, 864, 3)\n        predictions = tf.expand_dims(predictions, axis=-1) # Example shape (self.blocks_counter+pad_value, 864, 3, 1)\n        predictions = tf.transpose(predictions, perm=[0, 1, 3, 2]) # Example shape (self.blocks_counter+pad_value, 864, 1, 3)\n        predictions = tf.tile(predictions, multiples=[1, 1, CFG['patch_size'], 1]) # Example shape (self.blocks_counter+pad_value, 864, 18, 3)\n        predictions = tf.reshape(predictions, shape=(predictions.shape[0], predictions.shape[1]*predictions.shape[2], 3)) # Example shape (self.blocks_counter+pad_value, 15552, 3)\n        predictions = predictions.numpy()\n        \n        '''\n        The following function aggregates predictions blocks and creates dataframes with StartHesitation_prediction, Turn_prediction, Walking_prediction columns.\n        \n        '''\n        \n        def create_target(description):\n            series, series_blocks = description['series'].copy(), description['series_blocks']\n            \n            values = np.zeros((series_blocks[-1][2], 4))\n            for series_block in series_blocks:\n                i, begin, end = series_block\n                values[begin:end, 0:3] += predictions[i]\n                values[begin:end, 3] += 1\n\n            values = values[:len(series)]\n            \n            series['StartHesitation_prediction'] = values[:,0] / values[:, 3]\n            series['Turn_prediction'] = values[:, 1] / values[:, 3]\n            series['Walking_prediction'] = values[:, 2] / values[:, 3]\n            series['Prediction_count'] = values[:, 3]\n            series['Event_prediction'] = series[['StartHesitation_prediction', 'Turn_prediction', 'Walking_prediction']].aggregate('max', axis=1)\n            \n            return series\n            \n        targets = Parallel(n_jobs=-1)(delayed(create_target)(self.descriptions[i]) for i in tqdm(range(len(self.descriptions)), disable=1-self.verbose))\n        targets = pd.concat(targets)\n        \n        return targets","metadata":{"execution":{"iopub.status.busy":"2023-06-25T20:31:33.458090Z","iopub.execute_input":"2023-06-25T20:31:33.460363Z","iopub.status.idle":"2023-06-25T20:31:39.514838Z","shell.execute_reply.started":"2023-06-25T20:31:33.460327Z","shell.execute_reply":"2023-06-25T20:31:39.513471Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\n[EventPredictionFnCallback Initialization] [Series] 1 [Blocks] 1\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Predicitions: Tfog\n\nHere we run PredictionFnCallback on the test set.","metadata":{}},{"cell_type":"code","source":"for Id in tsfog_ids:\n    targets = PredictionFnCallback(prediction_ids=[Id], model=model).prediction()\n    submission = pd.DataFrame({'Id': (targets['Id'].values + '_' + targets['Time'].astype('str')).values,\n                               'StartHesitation': targets['StartHesitation_prediction'].values,\n                               'Turn': targets['Turn_prediction'].values,\n                               'Walking': targets['Walking_prediction'].values,\n                              })\n    \n    all_submissions.append(submission)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model: Defog\nThis is the same model design, but utilizes only the defog dataset. Please refer to the tfog description for more details.","metadata":{}},{"cell_type":"code","source":"CFG = {'TPU': 0,\n       'block_size': 12096, \n       'block_stride': 12096//16,\n       'patch_size': 14, \n       \n       'fog_model_dim': 320,\n       'fog_model_num_heads': 6,\n       'fog_model_num_encoder_layers': 5,\n       'fog_model_num_lstm_layers': 2,\n       'fog_model_first_dropout': 0.1,\n       'fog_model_encoder_dropout': 0.1,\n       'fog_model_mha_dropout': 0.0,\n      }\n\nassert CFG['block_size'] % CFG['patch_size'] == 0\nassert CFG['block_size'] % CFG['block_stride'] == 0\n\ndef sample_normalize(sample):\n    mean = tf.math.reduce_mean(sample)\n    std = tf.math.reduce_std(sample)\n    sample = tf.math.divide_no_nan(sample-mean, std)\n    \n    return sample.numpy()\n\ndef get_blocks(series, columns):\n    series = series.copy()\n    series = series[columns]\n    series = series.values\n    series = series.astype(np.float32)\n    \n    block_count = math.ceil(len(series) / CFG['block_size'])\n    \n    series = np.pad(series, pad_width=[[0, block_count*CFG['block_size']-len(series)], [0, 0]])\n    \n    block_begins = list(range(0, len(series), CFG['block_stride']))\n    block_begins = [x for x in block_begins if x+CFG['block_size'] <= len(series)]\n    \n    blocks = []\n    for begin in block_begins:\n        values = series[begin:begin+CFG['block_size']]\n        blocks.append({'begin': begin,\n                       'end': begin+CFG['block_size'],\n                       'values': values})\n    \n    return blocks\n\n\nGPU_BATCH_SIZE = 4\nTPU_BATCH_SIZE = GPU_BATCH_SIZE*8\n\nclass EncoderLayer(tf.keras.layers.Layer):\n    def __init__(self):\n        super().__init__()\n        \n        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=CFG['fog_model_num_heads'], key_dim=CFG['fog_model_dim'], dropout=CFG['fog_model_mha_dropout'])\n        \n        self.add = tf.keras.layers.Add()\n        \n        self.layernorm = tf.keras.layers.LayerNormalization()\n        \n        self.seq = tf.keras.Sequential([tf.keras.layers.Dense(CFG['fog_model_dim'], activation='relu'), \n                                        tf.keras.layers.Dropout(CFG['fog_model_encoder_dropout']), \n                                        tf.keras.layers.Dense(CFG['fog_model_dim']), \n                                        tf.keras.layers.Dropout(CFG['fog_model_encoder_dropout']),\n                                       ])\n        \n    def call(self, x):\n        attn_output = self.mha(query=x, key=x, value=x)\n        x = self.add([x, attn_output])\n        x = self.layernorm(x)\n        x = self.add([x, self.seq(x)])\n        x = self.layernorm(x)\n        \n        return x\n    \nclass FOGEncoder(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        \n        self.first_linear = tf.keras.layers.Dense(CFG['fog_model_dim'])\n        \n        self.add = tf.keras.layers.Add()\n        \n        self.first_dropout = tf.keras.layers.Dropout(CFG['fog_model_first_dropout'])\n        \n        self.enc_layers = [EncoderLayer() for _ in range(CFG['fog_model_num_encoder_layers'])]\n        \n        self.lstm_layers = [tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(CFG['fog_model_dim'], return_sequences=True)) for _ in range(CFG['fog_model_num_lstm_layers'])]\n        \n        self.sequence_len = CFG['block_size'] // CFG['patch_size']\n        self.pos_encoding = tf.Variable(initial_value=tf.random.normal(shape=(1, self.sequence_len, CFG['fog_model_dim']), stddev=0.02), trainable=True)\n        \n    def call(self, x, training=None): \n        x = x / 50.0 \n        x = self.first_linear(x) \n          \n        if training: # augmentation by randomly roll of the position encoding tensor\n            random_pos_encoding = tf.roll(tf.tile(self.pos_encoding, multiples=[GPU_BATCH_SIZE, 1, 1]), \n                                          shift=tf.random.uniform(shape=(GPU_BATCH_SIZE,), minval=-self.sequence_len, maxval=0, dtype=tf.int32),\n                                          axis=GPU_BATCH_SIZE * [1],\n                                          )\n            x = self.add([x, random_pos_encoding])\n        \n        else: # without augmentation \n            x = self.add([x, tf.tile(self.pos_encoding, multiples=[GPU_BATCH_SIZE, 1, 1])])\n            \n        x = self.first_dropout(x)\n        \n        for i in range(CFG['fog_model_num_encoder_layers']): x = self.enc_layers[i](x) \n        for i in range(CFG['fog_model_num_lstm_layers']): x = self.lstm_layers[i](x) \n            \n        return x\n    \nclass FOGModel(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        \n        self.encoder = FOGEncoder()\n        self.last_linear = tf.keras.layers.Dense(4) \n        \n    def call(self, x): \n        x = self.encoder(x) \n        x = self.last_linear(x) \n        x = tf.nn.sigmoid(x)\n        \n        return x\n\nWEIGHTS = '/kaggle/input/defog-freezing-gait-models/025_0.355_0.816_0.1436_model.h5' # DEFOG weights\n\nmodel = FOGModel()\nmodel.build(input_shape=(GPU_BATCH_SIZE, CFG['block_size'] // CFG['patch_size'], CFG['patch_size']*3))\nif len(WEIGHTS): model.load_weights(WEIGHTS)","metadata":{"execution":{"iopub.status.busy":"2023-06-25T20:31:39.518835Z","iopub.execute_input":"2023-06-25T20:31:39.519157Z","iopub.status.idle":"2023-06-25T20:31:42.722708Z","shell.execute_reply.started":"2023-06-25T20:31:39.519126Z","shell.execute_reply":"2023-06-25T20:31:42.721737Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### PredicitionFnCallback and Predictions: Defog","metadata":{}},{"cell_type":"code","source":"class PredictionFnCallback(tf.keras.callbacks.Callback):\n    \n    def __init__(self, prediction_ids, model=None, verbose=0):\n        \n        if not model is None: self.model = model\n        self.verbose = verbose\n         \n        def init(Id, path):\n            series = pd.read_csv(path).reset_index(drop=True)\n            series['Id'] = Id\n            series['AccV'] = sample_normalize(series['AccV'].values)\n            series['AccML'] = sample_normalize(series['AccML'].values)\n            series['AccAP'] = sample_normalize(series['AccAP'].values)\n            \n            series_blocks=[]\n            for block in get_blocks(series, ['AccV', 'AccML', 'AccAP']): \n                values = tf.reshape(block['values'], shape=(CFG['block_size'] // CFG['patch_size'], CFG['patch_size'], 3)) \n                values = tf.reshape(values, shape=(CFG['block_size'] // CFG['patch_size'], CFG['patch_size']*3)) \n                values = tf.expand_dims(values, axis=0) \n                \n                self.blocks.append(values)\n                series_blocks.append((self.blocks_counter, block['begin'], block['end']))\n                self.blocks_counter += 1\n            \n            description = {}\n            description['series'] = series\n            description['series_blocks'] = series_blocks\n            self.descriptions.append(description)\n            \n        self.descriptions = [] \n        self.blocks = [] \n        self.blocks_counter=0 \n                \n        defog_ids = prediction_ids\n        defog_paths = [f'/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/defog/{defog_id}.csv' for defog_id in defog_ids]\n        for defog_id, defog_path in tqdm(zip(defog_ids, defog_paths), total=len(defog_ids), desc='PredictionFnCallback Initialization', disable=1-verbose): \n            init(defog_id, defog_path)\n                \n        self.blocks = tf.concat(self.blocks, axis=0)  \n        \n        '''\n        self.blocks is padded so that the final length is divisible by inference batch size for error-free operation of model.predict function\n        Padded values have no effect on the predictions\n        \n        '''\n        \n        self.blocks = tf.pad(self.blocks, \n                             paddings=[[0, math.ceil(self.blocks_counter / (TPU_BATCH_SIZE if CFG['TPU'] else GPU_BATCH_SIZE))*(TPU_BATCH_SIZE if CFG['TPU'] else GPU_BATCH_SIZE)-self.blocks_counter], \n                                                    [0, 0], \n                                                    [0, 0],\n                                      ]) \n        \n        print(f'\\n[PredictionFnCallback Initialization] [Series] {len(self.descriptions)} [Blocks] {self.blocks_counter}\\n')\n    \n    def prediction(self):\n        predictions = model.predict(self.blocks, batch_size=TPU_BATCH_SIZE if CFG['TPU'] else GPU_BATCH_SIZE, verbose=self.verbose) # Example shape (self.blocks_counter+pad_value, 864, 4)\n        predictions = predictions[:, :, :3] \n        predictions = tf.expand_dims(predictions, axis=-1) \n        predictions = tf.transpose(predictions, perm=[0, 1, 3, 2]) \n        predictions = tf.tile(predictions, multiples=[1, 1, CFG['patch_size'], 1]) \n        predictions = tf.reshape(predictions, shape=(predictions.shape[0], predictions.shape[1]*predictions.shape[2], 3)) \n        predictions = predictions.numpy()\n        \n        '''\n        The following function aggregates predictions blocks and creates dataframes with StartHesitation_prediction, Turn_prediction, Walking_prediction columns.\n        \n        '''\n        \n        def create_target(description):\n            series, series_blocks = description['series'].copy(), description['series_blocks']\n            \n            values = np.zeros((series_blocks[-1][2], 4))\n            for series_block in series_blocks:\n                i, begin, end = series_block\n                values[begin:end, 0:3] += predictions[i]\n                values[begin:end, 3] += 1\n\n            values = values[:len(series)]\n            \n            series['StartHesitation_prediction'] = values[:, 0] / values[:, 3]\n            series['Turn_prediction'] = values[:, 1] / values[:, 3]\n            series['Walking_prediction'] = values[:, 2] / values[:, 3]\n            series['Prediction_count'] = values[:, 3]\n            \n            return series\n            \n        targets = Parallel(n_jobs=-1)(delayed(create_target)(self.descriptions[i]) for i in tqdm(range(len(self.descriptions)), disable=1-self.verbose))\n        targets = pd.concat(targets).reset_index(drop=True)\n        \n        return targets\n\n\nfor Id in defog_ids:\n    targets = PredictionFnCallback(prediction_ids=[Id], model=model).prediction()\n    submission = pd.DataFrame({'Id': (targets['Id'].values + '_' + targets['Time'].astype('str')).values,\n                               'StartHesitation': targets['StartHesitation_prediction'].values,\n                               'Turn': targets['Turn_prediction'].values,\n                               'Walking': targets['Walking_prediction'].values,\n                              })\n    \n    all_submissions.append(submission)","metadata":{"execution":{"iopub.status.busy":"2023-06-25T20:31:42.726530Z","iopub.execute_input":"2023-06-25T20:31:42.726848Z","iopub.status.idle":"2023-06-25T20:32:07.143778Z","shell.execute_reply.started":"2023-06-25T20:31:42.726822Z","shell.execute_reply":"2023-06-25T20:32:07.142798Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\n[PredictionFnCallback Initialization] [Series] 1 [Blocks] 369\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Submission:\n\nThe dataframes of the predicted values for both datasets can be concated below. If you decided to create multiple models, this allows for the averaging of values for your final submission. Again, I can not thank [Baurzhan Urazalinov](https://www.kaggle.com/baurzhanurazalinov) for his help here enough. It was a great learning experience.","metadata":{}},{"cell_type":"code","source":"submission = pd.concat(all_submissions).reset_index(drop=True)\nsubmission = submission.groupby('Id').agg('mean').reset_index()\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-25T20:32:07.145430Z","iopub.execute_input":"2023-06-25T20:32:07.145811Z","iopub.status.idle":"2023-06-25T20:32:10.007197Z","shell.execute_reply.started":"2023-06-25T20:32:07.145768Z","shell.execute_reply":"2023-06-25T20:32:10.006166Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion:\n\nWorking with this dataset was extremely challenging for me. The community helped quiet a bit and there experience helped me learn more about using the TensorFlow API.\n\nThe EDTA was quiet helpful in realizing some form of memory was necassary and I immediately thought of LSTMs. [Baurzhan Urazalinov](https://www.kaggle.com/baurzhanurazalinov) work on pointing out transforms was extremely helpful and made this possible.\n\nThe best solutions are at >0.5 at this time. \n\nFuture steps:\n- Hypertuning parameters\n- Potentionally combining both datasets\n- Using a TPU, which I was unable to do this iteration\n- The notype dataset was never used, I am curious if people thought of incorporating this data in an unsupervised way\n- Personally, learning more about tensorflow and different models being developed by Google Brain","metadata":{}}]}